#!/usr/bin/env python3
"""
Ph√¢n t√≠ch chi ti·∫øt ƒë·ªÉ ph√°t hi·ªán l·ªói logic trong LaTeX Question Parser
"""

import pandas as pd
import json
import re
import os
import sys
from typing import List, Dict, Any

# Add current directory to path
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

def analyze_parsing_logic():
    """Ph√¢n t√≠ch chi ti·∫øt logic parsing."""
    
    print("üîç PH√ÇN T√çCH CHI TI·∫æT L·ªñI LOGIC PARSING")
    print("=" * 60)
    
    # Load d·ªØ li·ªáu
    output_dir = "output"
    questions_path = os.path.join(output_dir, "questions.csv")
    
    if not os.path.exists(questions_path):
        print("‚ùå Kh√¥ng t√¨m th·∫•y file questions.csv")
        return
    
    df = pd.read_csv(questions_path)
    print(f"üìä Loaded {len(df)} questions")
    
    # 1. Ph√¢n t√≠ch n·ªôi dung b·ªã c·∫Øt ho·∫∑c kh√¥ng ƒë·∫ßy ƒë·ªß
    print("\n1Ô∏è‚É£ PH√ÇN T√çCH N·ªòI DUNG B·ªä C·∫ÆT")
    print("-" * 40)
    
    # T√¨m c√¢u h·ªèi c√≥ n·ªôi dung qu√° ng·∫Øn
    short_content = df[df['content'].str.len() < 50]
    print(f"‚ùå {len(short_content)} c√¢u h·ªèi c√≥ n·ªôi dung < 50 k√Ω t·ª±")
    
    if not short_content.empty:
        print("M·∫´u c√¢u h·ªèi c√≥ n·ªôi dung ng·∫Øn:")
        for idx, row in short_content.head(3).iterrows():
            print(f"  ID {row['id']}: '{row['content'][:100]}...'")
    
    # 2. Ph√¢n t√≠ch ƒë√°p √°n kh√¥ng ƒë∆∞·ª£c tr√≠ch xu·∫•t ƒë√∫ng
    print("\n2Ô∏è‚É£ PH√ÇN T√çCH ƒê√ÅP √ÅN")
    print("-" * 40)
    
    # C√¢u h·ªèi kh√¥ng c√≥ ƒë√°p √°n
    no_answers = df[df['answers'].isna() | (df['answers'].str.strip() == '')]
    print(f"‚ùå {len(no_answers)} c√¢u h·ªèi kh√¥ng c√≥ ƒë√°p √°n")
    
    # C√¢u h·ªèi kh√¥ng c√≥ ƒë√°p √°n ƒë√∫ng
    no_correct = df[df['correctAnswer'].isna() | (df['correctAnswer'].str.strip() == '')]
    print(f"‚ùå {len(no_correct)} c√¢u h·ªèi kh√¥ng c√≥ ƒë√°p √°n ƒë√∫ng")
    
    # Ph√¢n t√≠ch format ƒë√°p √°n
    answer_formats = {}
    for idx, row in df.head(100).iterrows():  # Ch·ªâ ph√¢n t√≠ch 100 c√¢u ƒë·∫ßu
        if pd.notna(row['answers']) and row['answers'].strip():
            try:
                answers = json.loads(row['answers'])
                if isinstance(answers, list) and answers:
                    first_answer = answers[0]
                    if isinstance(first_answer, dict):
                        format_key = "dict_format"
                    else:
                        format_key = "string_format"
                    answer_formats[format_key] = answer_formats.get(format_key, 0) + 1
            except:
                answer_formats['invalid_json'] = answer_formats.get('invalid_json', 0) + 1
    
    print("Format ƒë√°p √°n:")
    for format_type, count in answer_formats.items():
        print(f"  - {format_type}: {count}")
    
    # 3. Ph√¢n t√≠ch LaTeX commands kh√¥ng ƒë∆∞·ª£c x·ª≠ l√Ω
    print("\n3Ô∏è‚É£ PH√ÇN T√çCH LATEX COMMANDS")
    print("-" * 40)
    
    latex_patterns = [
        (r'\\begin\{[^}]+\}', 'begin environments'),
        (r'\\end\{[^}]+\}', 'end environments'),
        (r'\\choice[A-Z]*', 'choice commands'),
        (r'\\True', 'True markers'),
        (r'\\loigiai', 'solution markers'),
        (r'\\[a-zA-Z]+\{', 'other commands with braces')
    ]
    
    for pattern, description in latex_patterns:
        matches = df['content'].str.contains(pattern, na=False).sum()
        if matches > 0:
            print(f"‚ùå {matches} c√¢u h·ªèi c√≤n ch·ª©a {description}")
    
    # 4. Ph√¢n t√≠ch lo·∫°i c√¢u h·ªèi
    print("\n4Ô∏è‚É£ PH√ÇN T√çCH LO·∫†I C√ÇU H·ªéI")
    print("-" * 40)
    
    type_counts = df['type'].value_counts()
    print("Ph√¢n b·ªë lo·∫°i c√¢u h·ªèi:")
    for qtype, count in type_counts.items():
        print(f"  - {qtype}: {count:,} c√¢u")
    
    # Ki·ªÉm tra logic ph√¢n lo·∫°i
    # TF questions should have True/False answers
    tf_questions = df[df['type'] == 'TF']
    if not tf_questions.empty:
        print(f"\nKi·ªÉm tra c√¢u h·ªèi TF ({len(tf_questions)} c√¢u):")
        tf_with_multiple_answers = 0
        for idx, row in tf_questions.head(10).iterrows():
            if pd.notna(row['answers']):
                try:
                    answers = json.loads(row['answers'])
                    if len(answers) > 2:
                        tf_with_multiple_answers += 1
                except:
                    pass
        if tf_with_multiple_answers > 0:
            print(f"  ‚ö†Ô∏è {tf_with_multiple_answers}/10 c√¢u TF c√≥ >2 ƒë√°p √°n (c√≥ th·ªÉ sai lo·∫°i)")
    
    # 5. Ph√¢n t√≠ch solution extraction
    print("\n5Ô∏è‚É£ PH√ÇN T√çCH TR√çCH XU·∫§T L·ªúI GI·∫¢I")
    print("-" * 40)
    
    has_solution = df['solution'].notna() & (df['solution'].str.strip() != '')
    print(f"‚úÖ {has_solution.sum()}/{len(df)} c√¢u h·ªèi c√≥ l·ªùi gi·∫£i ({has_solution.mean()*100:.1f}%)")
    
    # Ki·ªÉm tra solution c√≥ ch·ª©a LaTeX commands
    if has_solution.any():
        solutions_with_latex = df[has_solution]['solution'].str.contains(r'\\[a-zA-Z]+', na=False).sum()
        print(f"‚ö†Ô∏è {solutions_with_latex} l·ªùi gi·∫£i c√≤n ch·ª©a LaTeX commands")

def compare_with_original_detailed():
    """So s√°nh chi ti·∫øt v·ªõi file g·ªëc."""
    
    print("\nüîÑ SO S√ÅNH CHI TI·∫æT V·ªöI FILE G·ªêC")
    print("=" * 60)
    
    original_file = "tests/10-11.so1-17-24-25.md"
    
    if not os.path.exists(original_file):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file g·ªëc: {original_file}")
        return
    
    # ƒê·ªçc file g·ªëc
    with open(original_file, 'r', encoding='utf-8') as f:
        original_content = f.read()
    
    print(f"üìÑ File g·ªëc: {len(original_content):,} k√Ω t·ª±")
    
    # T√¨m t·∫•t c·∫£ c√¢u h·ªèi trong file g·ªëc
    ex_pattern = r'\\begin\{ex\}.*?\\end\{ex\}'
    original_questions = re.findall(ex_pattern, original_content, re.DOTALL)
    
    print(f"üìä T√¨m th·∫•y {len(original_questions)} c√¢u h·ªèi trong file g·ªëc")
    
    # Load parsed data
    df = pd.read_csv("output/questions.csv")
    print(f"üìä ƒê√£ parse {len(df)} c√¢u h·ªèi")
    
    # So s√°nh s·ªë l∆∞·ª£ng
    if len(original_questions) != len(df):
        print(f"‚ö†Ô∏è S·ªë l∆∞·ª£ng kh√¥ng kh·ªõp: G·ªëc {len(original_questions)} vs Parsed {len(df)}")
    
    # Ph√¢n t√≠ch c√¢u h·ªèi ƒë·∫ßu ti√™n
    if original_questions:
        print("\nüìù PH√ÇN T√çCH C√ÇU H·ªéI ƒê·∫¶U TI√äN:")
        print("-" * 40)
        
        first_original = original_questions[0]
        print("üî∏ C√¢u h·ªèi g·ªëc:")
        print(first_original[:500] + "..." if len(first_original) > 500 else first_original)
        
        if not df.empty:
            first_parsed = df.iloc[0]
            print("\nüî∏ C√¢u h·ªèi ƒë√£ parse:")
            print(f"Content: {first_parsed['content'][:300]}...")
            print(f"Type: {first_parsed['type']}")
            print(f"Answers: {first_parsed['answers'][:200] if pd.notna(first_parsed['answers']) else 'None'}...")
            print(f"Correct: {first_parsed['correctAnswer'][:200] if pd.notna(first_parsed['correctAnswer']) else 'None'}...")
    
    # Ph√¢n t√≠ch patterns trong file g·ªëc
    print("\nüîç PH√ÇN T√çCH PATTERNS TRONG FILE G·ªêC:")
    print("-" * 40)
    
    patterns_to_check = [
        (r'\\choiceTF', 'choiceTF commands'),
        (r'\\choice(?!TF)', 'choice commands'),
        (r'\\shortans', 'shortans commands'),
        (r'\\True', 'True markers'),
        (r'\\loigiai\{', 'solution blocks'),
        (r'%\[([^\]]+)\]', 'question codes')
    ]
    
    for pattern, description in patterns_to_check:
        matches = re.findall(pattern, original_content)
        print(f"  - {description}: {len(matches)} l·∫ßn xu·∫•t hi·ªán")
        if matches and len(matches) <= 5:
            print(f"    V√≠ d·ª•: {matches[:3]}")

def main():
    """Main analysis function."""
    analyze_parsing_logic()
    compare_with_original_detailed()
    
    print("\n" + "=" * 60)
    print("üéØ K·∫æT LU·∫¨N:")
    print("H√£y m·ªü giao di·ªán Streamlit t·∫°i http://localhost:8503 ƒë·ªÉ xem chi ti·∫øt")
    print("v√† so s√°nh k·∫øt qu·∫£ parsing v·ªõi d·ªØ li·ªáu g·ªëc.")

if __name__ == "__main__":
    main()
